{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook evaluates the performance of adversarial patches (i.e. noise, black, checker, and universal (trained))."
      ],
      "metadata": {
        "id": "9cdGplBWAJ5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "Imports, Installations, and Downloads"
      ],
      "metadata": {
        "id": "e_ApF0qF8b15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil; shutil.rmtree(\"/root/fiftyone/open-images-v7/\", ignore_errors=True)"
      ],
      "metadata": {
        "id": "zDumk1gCuIIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyuPRP4b-jBQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers timm torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tfds-nightly tensorflow matplotlib"
      ],
      "metadata": {
        "id": "aByYPnjhwvTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import requests\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "\n",
        "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "db9Qh3T7-9E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "6g4Wx5tzEVGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U fiftyone"
      ],
      "metadata": {
        "id": "BTwdeMQQ0sF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz"
      ],
      "metadata": {
        "id": "_gPcdv_v0pYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = foz.load_zoo_dataset(\n",
        "    \"open-images-v7\",\n",
        "    split=\"validation\",\n",
        "    max_samples=100,\n",
        "    seed=51,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "extra = foz.load_zoo_dataset(\n",
        "    \"open-images-v7\",\n",
        "    split=\"test\",\n",
        "    max_samples=400,\n",
        "    seed=70,\n",
        "    shuffle=True\n",
        ")\n",
        "dataset.add_samples(extra)\n"
      ],
      "metadata": {
        "id": "Cix-X1ER0vGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a sample from dataset\n",
        "sample = dataset.first()\n",
        "image = Image.open(sample.filepath).convert(\"RGB\")"
      ],
      "metadata": {
        "id": "V9gRS8IP4n0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.ops as ops\n",
        "import matplotlib.patches as patches\n",
        "import csv"
      ],
      "metadata": {
        "id": "0fa97WvDO_lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Patches & Define Helper Functions"
      ],
      "metadata": {
        "id": "Zsh6WU_l9Etf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum of the distances the bounding boxes moved\n",
        "def detections_distances(clean_outputs, patched_outputs, threshold=0.0):\n",
        "    clean_probs = clean_outputs.logits[0].softmax(-1)\n",
        "    patched_probs = patched_outputs.logits[0].softmax(-1)\n",
        "\n",
        "    clean_keep = clean_probs.max(-1).values > threshold\n",
        "    patched_keep = patched_probs.max(-1).values > threshold\n",
        "\n",
        "    clean_boxes = clean_outputs.pred_boxes[0][clean_keep][:, :2]  # cx, cy\n",
        "    patched_boxes = patched_outputs.pred_boxes[0][patched_keep][:, :2]\n",
        "\n",
        "    distances = []\n",
        "    if clean_boxes.shape[0] != 0 and patched_boxes.shape[0] != 0:\n",
        "      for i, clean_center in enumerate(clean_boxes):\n",
        "          dists = torch.norm(patched_boxes - clean_center, dim=1)\n",
        "          min_dist = dists.min().item()\n",
        "          distances.append(min_dist)\n",
        "    return sum(distances)\n"
      ],
      "metadata": {
        "id": "bSS1aXgPdhpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "    T.Resize((480, 640)),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "# Helper functions for comparing adversarial/clean results\n",
        "def apply_patch(img, patch, x=300, y=200):\n",
        "    img_clone = img.clone()\n",
        "    img_clone[:, :, y:y+patch_size, x:x+patch_size] = patch\n",
        "    return img_clone\n",
        "\n",
        "def count_real_detections(outputs, threshold=0.5, no_object_class=91):\n",
        "    probs = outputs.logits[0].softmax(-1)\n",
        "    scores, labels = probs.max(-1)\n",
        "    return ((scores > threshold) & (labels != no_object_class)).sum().item()\n",
        "\n",
        "def get_boxes(outputs, conf_thresh=0.9, no_object_class=91):\n",
        "    probs = outputs.logits[0].softmax(-1)\n",
        "    scores, labels = probs.max(-1)\n",
        "    keep = (scores > conf_thresh) & (labels != no_object_class)\n",
        "    boxes = outputs.pred_boxes[0][keep]\n",
        "    H, W = 480, 640\n",
        "    boxes_xyxy = []\n",
        "    for box in boxes:\n",
        "        cx, cy, w, h = box\n",
        "        x0 = (cx - w/2) * W\n",
        "        y0 = (cy - h/2) * H\n",
        "        x1 = (cx + w/2) * W\n",
        "        y1 = (cy + h/2) * H\n",
        "        boxes_xyxy.append([x0.item(), y0.item(), x1.item(), y1.item()])\n",
        "    return torch.tensor(boxes_xyxy)\n",
        "\n",
        "def box_suppression_ratio(clean_boxes, patched_boxes, iou_thresh=0.5):\n",
        "    if len(clean_boxes) == 0:\n",
        "        return 0.0\n",
        "    iou_matrix = ops.box_iou(clean_boxes, patched_boxes)\n",
        "    max_iou_per_clean = iou_matrix.max(dim=1).values\n",
        "    unmatched = (max_iou_per_clean < iou_thresh).sum().item()\n",
        "    return unmatched / len(clean_boxes)\n",
        "\n",
        "def detection_entropy(outputs):\n",
        "    probs = outputs.logits[0].softmax(-1)\n",
        "    entropies = -torch.sum(probs * probs.log(), dim=-1)\n",
        "    return entropies.mean().item()\n",
        "\n",
        "def show_detections(img_tensor, outputs, title):\n",
        "    img = img_tensor.squeeze().permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "    boxes = outputs.pred_boxes[0].detach().cpu()\n",
        "    probs = outputs.logits[0].softmax(-1).detach().cpu()\n",
        "    keep = probs.max(-1).values > 0.9\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img)\n",
        "    H, W = img_tensor.shape[-2:]\n",
        "\n",
        "    for box in boxes[keep]:\n",
        "        cx, cy, w, h = box\n",
        "        x0 = (cx - w/2) * W\n",
        "        y0 = (cy - h/2) * H\n",
        "        rect = patches.Rectangle((x0, y0), w*W, h*H, edgecolor='red', facecolor='none', linewidth=2)\n",
        "        plt.gca().add_patch(rect)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "3oSF66gX6E-6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 80\n",
        "tile_size = 10\n",
        "\n",
        "# Baseline patches\n",
        "black_patch = torch.zeros((1, 3, patch_size, patch_size)).to(device)\n",
        "checkered_patch = (((torch.arange(patch_size).unsqueeze(1) // tile_size +\n",
        "              torch.arange(patch_size).unsqueeze(0) // tile_size) % 2)\n",
        "            .float().unsqueeze(0).repeat(3,1,1).unsqueeze(0)).to(device)\n",
        "noisy_patch = torch.rand((1, 3, patch_size, patch_size)).to(device)\n",
        "\n",
        "# Trained patch\n",
        "optim_patch = checkered_patch.clone().detach() # checkered start; seems to work best\n",
        "optim_patch = optim_patch.to(device)\n",
        "optim_patch.requires_grad = True\n",
        "optimizer = torch.optim.Adam([optim_patch], lr=0.8e-2)"
      ],
      "metadata": {
        "id": "xQbXsoaQqCAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Calculate the loss to maximize shifts in bounding boxes & differences in predictions\n",
        "def combined_loss(clean_outputs, patched_outputs):\n",
        "    shift_loss = -detections_distances(clean_outputs, patched_outputs)\n",
        "\n",
        "    clean_probs = clean_outputs.logits.softmax(dim=-1)\n",
        "    patched_log_probs = F.log_softmax(patched_outputs.logits, dim=-1)\n",
        "    class_diff_loss = -F.kl_div(patched_log_probs, clean_probs, reduction='batchmean')\n",
        "\n",
        "    alpha = 0.5\n",
        "    beta = 1\n",
        "    total_loss = alpha * class_diff_loss + beta * shift_loss\n",
        "    return total_loss\n",
        "\n",
        "# Train the patch\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    for sample in dataset[100:]: # 400 samples total\n",
        "        image = Image.open(sample.filepath).convert(\"RGB\")\n",
        "        img_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        patched_img = apply_patch(img_tensor, optim_patch).to(device)\n",
        "        clean_outputs = model(img_tensor)\n",
        "        patched_outputs = model(patched_img)\n",
        "        loss = combined_loss(clean_outputs, patched_outputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optim_patch.data.clamp_(0, 1)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(dataset[100:])\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for sample in dataset[25:100]: # 75 samples\n",
        "            image = Image.open(sample.filepath).convert(\"RGB\")\n",
        "            img_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "            patched_img = apply_patch(img_tensor, optim_patch).to(device)\n",
        "            clean_outputs = model(img_tensor)\n",
        "            patched_outputs = model(patched_img)\n",
        "            val_loss = combined_loss(clean_outputs, patched_outputs)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(dataset[25:100])\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} completed, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "EbS4OqxUxADx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa1abc2-fa45-49af-cb32-7c902b851a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 completed, Train Loss: -52.8710, Validation Loss: -108.2958\n",
            "Epoch 2 completed, Train Loss: -115.0496, Validation Loss: -138.8757\n",
            "Epoch 3 completed, Train Loss: -129.1578, Validation Loss: -150.9644\n",
            "Epoch 4 completed, Train Loss: -134.8828, Validation Loss: -156.1643\n",
            "Epoch 5 completed, Train Loss: -139.9937, Validation Loss: -162.6386\n",
            "Epoch 6 completed, Train Loss: -147.1126, Validation Loss: -164.2050\n",
            "Epoch 7 completed, Train Loss: -152.4851, Validation Loss: -172.6912\n",
            "Epoch 8 completed, Train Loss: -155.7269, Validation Loss: -173.9079\n",
            "Epoch 9 completed, Train Loss: -157.3030, Validation Loss: -174.9588\n",
            "Epoch 10 completed, Train Loss: -158.4956, Validation Loss: -181.5939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save patch\n",
        "final_patch = optim_patch\n",
        "torch.save(final_patch, \"final_patch.pt\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1t8VWSMdkluR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze Patches\n",
        "Analyze patch on test set (+ visualize bounding boxes)"
      ],
      "metadata": {
        "id": "WPsuFFdK9VQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print/save analysis of the effects of the patch\n",
        "def analyze_patch(patch, patch_name):\n",
        "    results = []\n",
        "    print(patch_name)\n",
        "\n",
        "    for sample in dataset[:25]:\n",
        "        image = Image.open(sample.filepath).convert(\"RGB\")\n",
        "        img_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            proc_clean = processor(images=img_tensor, return_tensors=\"pt\")\n",
        "            proc_clean = {k: v.to(device) for k, v in proc_clean.items()}\n",
        "            clean_outputs = model(**proc_clean)\n",
        "\n",
        "            patched_tensor = apply_patch(img_tensor, patch).to(device)\n",
        "            proc_patched = processor(images=patched_tensor, return_tensors=\"pt\")\n",
        "            proc_patched = {k: v.to(device) for k, v in proc_patched.items()}\n",
        "            patched_outputs = model(**proc_patched)\n",
        "\n",
        "        clean_boxes = get_boxes(clean_outputs)\n",
        "        patched_boxes = get_boxes(patched_outputs)\n",
        "\n",
        "        shift = detections_distances(clean_outputs, patched_outputs)\n",
        "        suppression_ratio = box_suppression_ratio(clean_boxes, patched_boxes)\n",
        "        entropy_clean = detection_entropy(clean_outputs)\n",
        "        entropy_patched = detection_entropy(patched_outputs)\n",
        "\n",
        "        # Compare predicted classes by argmax on logits\n",
        "        clean_logits = clean_outputs.logits\n",
        "        patched_logits = patched_outputs.logits\n",
        "\n",
        "        clean_preds = clean_logits.argmax(dim=-1).squeeze(0)\n",
        "        patched_preds = patched_logits.argmax(dim=-1).squeeze(0)\n",
        "\n",
        "        # Calculate how many predictions match\n",
        "        matches = (clean_preds == patched_preds).sum().item()\n",
        "        total_preds = clean_preds.shape[0]\n",
        "        match_ratio = matches / total_preds if total_preds > 0 else 0.0\n",
        "\n",
        "        print(f\"{sample.filepath} — suppression: {suppression_ratio:.2f}, shift: {shift:.2f}, entropy: {entropy_clean:.2f} → {entropy_patched:.2f}, match_ratio: {match_ratio:.2f}\")\n",
        "\n",
        "        results.append({\n",
        "            \"filename\": sample.filepath,\n",
        "            \"suppression_ratio\": suppression_ratio,\n",
        "            \"sum_box_shift\": shift,\n",
        "            \"entropy_clean\": entropy_clean,\n",
        "            \"entropy_patched\": entropy_patched,\n",
        "            \"prediction_match_ratio\": match_ratio\n",
        "        })\n",
        "\n",
        "        show_detections(img_tensor, clean_outputs, \"Original\")\n",
        "        show_detections(patched_tensor, patched_outputs, \"After Patch\")\n",
        "\n",
        "    csv_path = \"/content/results_\" + patch_name + \".csv\"\n",
        "    with open(csv_path, \"w\", newline=\"\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=[\n",
        "            \"filename\",\n",
        "            \"suppression_ratio\", \"sum_box_shift\",\n",
        "            \"entropy_clean\", \"entropy_patched\", \"prediction_match_ratio\"\n",
        "        ])\n",
        "        writer.writeheader()\n",
        "        for row in results:\n",
        "            writer.writerow(row)\n"
      ],
      "metadata": {
        "id": "wmrYVUCx1aab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(optim_patch.device)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "analyze_patch(optim_patch, \"Optimized Patch\")"
      ],
      "metadata": {
        "id": "58-akBUj2H29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_patch(noisy_patch, \"Noisy Patch\")"
      ],
      "metadata": {
        "id": "QeYevKBYFHfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_patch(black_patch, \"Black Patch\")"
      ],
      "metadata": {
        "id": "1s-kk9bOFEe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_patch(checkered_patch, \"Checkered Patch\")"
      ],
      "metadata": {
        "id": "daer28WNFK5Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}